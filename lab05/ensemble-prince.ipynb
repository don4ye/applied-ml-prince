{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b994458d-e522-4ef0-8228-73e8ee86d027",
   "metadata": {},
   "source": [
    "# Lab 5: Ensemble Machine Learning – Wine Quality Dataset  \n",
    "**Name:** Prince  \n",
    "**Date:** 04/09/2025  \n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this project, I’m exploring different ensemble machine learning models to predict wine quality based on its chemical properties. The dataset comes from the UCI Machine Learning Repository and includes red wine samples rated by experts.\n",
    "\n",
    "Instead of using just one model, I’ll be combining the strengths of multiple models — like Random Forest and AdaBoost — to see if we can get better results. The goal is to figure out which approach gives us the most accurate and balanced predictions for classifying wine as **low**, **medium**, or **high** quality.\n",
    "\n",
    "I'll be checking the performance of each model using accuracy and F1 score, and also paying attention to whether the model overfits or generalizes well to new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2c4942-3f8a-474d-a403-3669ca24de0a",
   "metadata": {},
   "source": [
    "## Section 0: Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e1900b-c798-4764-851f-343bdf89cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 0: Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    BaggingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc1bc3a-4e4b-42de-b2cc-03c8b23d29b3",
   "metadata": {},
   "source": [
    "## Section 1: Load and Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b50a2fe2-aca7-4503-be94-1bcdfeafe118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Section 1: Load and Inspect the Data\n",
    "\n",
    "# Load the red wine dataset (semicolon-separated)\n",
    "df = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "\n",
    "# Check dataset structure\n",
    "df.info()\n",
    "\n",
    "# Preview the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2406d425-9de1-407f-8622-60ef3bca4267",
   "metadata": {},
   "source": [
    "## Section 2: Prepare the Data\n",
    "\n",
    "The original `quality` column gives a score from 0 to 10, but most wines fall between 3 and 8. Instead of using all those numbers, I’m grouping them into 3 categories to make the classification easier:\n",
    "\n",
    "- 3–4 = low quality  \n",
    "- 5–6 = medium quality  \n",
    "- 7–8 = high quality  \n",
    "\n",
    "I created two new columns:\n",
    "- `quality_label`: shows the category as text (low, medium, high)\n",
    "- `quality_numeric`: turns that into numbers (0, 1, 2) for the model\n",
    "\n",
    "This makes the target simpler and easier for the model to learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02a0cfe1-129e-41dc-baa3-e289ff256a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality_label\n",
       "medium    1319\n",
       "high       217\n",
       "low         63\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Section 2: Prepare the Data\n",
    "\n",
    "# Helper function to convert wine quality score to a label (string)\n",
    "def quality_to_label(q):\n",
    "    if q <= 4:\n",
    "        return \"low\"\n",
    "    elif q <= 6:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"high\"\n",
    "\n",
    "# Apply function to create new label column\n",
    "df[\"quality_label\"] = df[\"quality\"].apply(quality_to_label)\n",
    "\n",
    "# Helper function to convert wine quality score to a numeric class\n",
    "def quality_to_number(q):\n",
    "    if q <= 4:\n",
    "        return 0\n",
    "    elif q <= 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# Apply function to create numeric column\n",
    "df[\"quality_numeric\"] = df[\"quality\"].apply(quality_to_number)\n",
    "\n",
    "# Check the distribution of each label\n",
    "df[\"quality_label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1fc7dd-552d-4878-be4b-0f9097d41446",
   "metadata": {},
   "source": [
    "## Section 3: Feature Selection and Justification\n",
    "\n",
    "For this project, I’m using the 11 chemical properties (like acidity, sugar, alcohol, etc.) as input features.\n",
    "\n",
    "I dropped these columns:\n",
    "- `quality`: the original raw score (not needed anymore)\n",
    "- `quality_label`: the text version of the label (only used for display)\n",
    "- `quality_numeric`: this is our target, so we don’t want it in the features\n",
    "\n",
    "My target variable is `quality_numeric`, which has 3 classes: 0 = low, 1 = medium, 2 = high.\n",
    "This format works best with the models we'll train.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ef1d60-15f7-4444-b452-f8cbfe769d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1599, 11), (1599,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Section 3: Feature Selection\n",
    "\n",
    "# Features: all chemical properties only (drop target-related columns)\n",
    "X = df.drop(columns=[\"quality\", \"quality_label\", \"quality_numeric\"])\n",
    "\n",
    "# Target: use numeric quality for training\n",
    "y = df[\"quality_numeric\"]\n",
    "\n",
    "# Quick check on shapes\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbe58fb-58af-4632-98f5-91cf1ea27c27",
   "metadata": {},
   "source": [
    "## Section 4: Split the Data into Train and Test\n",
    "\n",
    "Now that we’ve selected our features and target, it’s time to split the dataset.  \n",
    "I’m using an 80/20 train-test split so the model can learn from most of the data but still be tested on unseen examples.\n",
    "\n",
    "I’m also using `stratify=y` to make sure the class distribution (low, medium, high) stays consistent in both the training and testing sets. This helps the model generalize better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0602f1eb-77f1-4b32-adca-f850e2400661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1279, 11), (320, 11), (1279,), (320,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Section 4: Split the Data into Train and Test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train/test split (stratify to preserve class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Check split shapes\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf28944d-be11-4c74-ad37-646192cc8c25",
   "metadata": {},
   "source": [
    "## Section 5: Evaluate Model Performance\n",
    "\n",
    "Now I’ll evaluate two ensemble models: Random Forest and AdaBoost. These models are designed to improve performance by combining the predictions of multiple learners.\n",
    "\n",
    "I’m using a helper function to:\n",
    "- Train the model\n",
    "- Predict on train and test sets\n",
    "- Print a confusion matrix\n",
    "- Calculate accuracy and F1 score\n",
    "- Save results for comparison\n",
    "\n",
    "### Models Chosen:\n",
    "1. **Random Forest (100 trees)** – builds multiple trees and averages their predictions.\n",
    "2. **AdaBoost (100 estimators)** – builds trees sequentially, with each new one correcting the last.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "580128f8-4ab1-4e47-bc0e-38a74f177786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest (100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 256   8]\n",
      " [  0  15  28]]\n",
      "Train Accuracy: 1.0000, Test Accuracy: 0.8875\n",
      "Train F1 Score: 1.0000, Test F1 Score: 0.8661\n",
      "\n",
      "AdaBoost (100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  1  12   0]\n",
      " [  5 240  19]\n",
      " [  0  20  23]]\n",
      "Train Accuracy: 0.8342, Test Accuracy: 0.8250\n",
      "Train F1 Score: 0.8209, Test F1 Score: 0.8158\n"
     ]
    }
   ],
   "source": [
    "# Section 5: Evaluate Model Performance\n",
    "\n",
    "# Helper function to train and evaluate models\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, results):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average=\"weighted\")\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average=\"weighted\")\n",
    "\n",
    "    print(f\"\\n{name} Results\")\n",
    "    print(\"Confusion Matrix (Test):\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"Model\": name,\n",
    "            \"Train Accuracy\": train_acc,\n",
    "            \"Test Accuracy\": test_acc,\n",
    "            \"Train F1\": train_f1,\n",
    "            \"Test F1\": test_f1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Create list to store results\n",
    "results = []\n",
    "\n",
    "# 1. Random Forest (100 trees)\n",
    "evaluate_model(\n",
    "    \"Random Forest (100)\",\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 2. AdaBoost (100 estimators)\n",
    "evaluate_model(\n",
    "    \"AdaBoost (100)\",\n",
    "    AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a619c5-5b4d-42bd-ad53-2e9fba0a9afa",
   "metadata": {},
   "source": [
    "## Section 6: Compare Results\n",
    "\n",
    "Now that both models have been evaluated, I’ll compare them side-by-side in a results table.\n",
    "\n",
    "I also added two extra columns:\n",
    "- **Accuracy Gap**: Difference between train and test accuracy\n",
    "- **F1 Gap**: Difference between train and test F1 score\n",
    "\n",
    "Smaller gaps are better — they mean the model is generalizing well and not overfitting to the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14f1d95e-3244-4143-95a2-33579dd1608d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of All Models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Test F1</th>\n",
       "      <th>Accuracy Gap</th>\n",
       "      <th>F1 Gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest (100)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866056</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.133944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost (100)</td>\n",
       "      <td>0.834246</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.820863</td>\n",
       "      <td>0.815803</td>\n",
       "      <td>0.009246</td>\n",
       "      <td>0.005060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train Accuracy  Test Accuracy  Train F1   Test F1  \\\n",
       "0  Random Forest (100)        1.000000         0.8875  1.000000  0.866056   \n",
       "1       AdaBoost (100)        0.834246         0.8250  0.820863  0.815803   \n",
       "\n",
       "   Accuracy Gap    F1 Gap  \n",
       "0      0.112500  0.133944  \n",
       "1      0.009246  0.005060  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Section 6: Compare Results\n",
    "\n",
    "# Turn list of results into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate generalization gaps\n",
    "results_df[\"Accuracy Gap\"] = results_df[\"Train Accuracy\"] - results_df[\"Test Accuracy\"]\n",
    "results_df[\"F1 Gap\"] = results_df[\"Train F1\"] - results_df[\"Test F1\"]\n",
    "\n",
    "# Sort by test accuracy (best performing at top)\n",
    "results_df = results_df.sort_values(by=\"Test Accuracy\", ascending=False)\n",
    "\n",
    "# Show summary table\n",
    "print(\"\\nSummary of All Models:\")\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6245a791-987e-4b94-89d8-d320463752e9",
   "metadata": {},
   "source": [
    "## Section 7: Conclusions and Insights\n",
    "\n",
    "In this lab, I evaluated two ensemble models — **Random Forest (100)** and **AdaBoost (100)** — to predict red wine quality using 11 chemical features. Both models performed well but in different ways.\n",
    "\n",
    "### My Results:\n",
    "- **Random Forest (100)** had the best test performance with **88.75% accuracy** and **0.8661 F1 score**, but it also had **perfect training scores**. This created a large gap, which suggests overfitting — the model may be memorizing the training data instead of generalizing to new data.\n",
    "- **AdaBoost (100)** had slightly lower test accuracy (**82.5%**) and F1 score (**0.8158**), but its train and test results were very close. This means it generalizes better and is less likely to overfit.\n",
    "\n",
    "### Comparison with Other Student Models:\n",
    "Looking at another student’s results:\n",
    "- **AdaBoost**: 82.5% accuracy, 0.816 F1 score (similar to mine — shows AdaBoost is stable across experiments).\n",
    "- **MLP Classifier**: 84.4% accuracy, 0.807 F1 score. Slightly better accuracy than AdaBoost, but lower F1 — which means it might not perform as well on underrepresented classes.\n",
    "\n",
    "This comparison confirms that **AdaBoost is a solid general-purpose model**, while **MLP and Random Forest** may need more tuning or regularization to avoid overfitting.\n",
    "\n",
    "### Key Takeaways:\n",
    "- **Random Forest** gives great performance, but the high training scores make me cautious. I would reduce tree depth or limit features to improve generalization.\n",
    "- **AdaBoost** may not be the flashiest, but it's consistent — and in real-world projects, consistency is gold.\n",
    "- **MLP Classifier** looks promising and is worth exploring further, especially with parameter tuning.\n",
    "\n",
    "### If this were a competition\n",
    "\n",
    "I’d tune Random Forest to reduce overfitting, try Gradient Boosting or Voting Classifiers, and fix the class imbalance. I’d also use cross-validation to make results more reliable.\n",
    "\n",
    "\n",
    "### Final Thoughts:\n",
    "My top pick for now is **AdaBoost** — not because it wins every metric, but because it shows **balanced performance** without overfitting. And as an analyst, I care about models that work just as well tomorrow as they do today.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26afa13a-fa7c-4f9d-b783-26a100320e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
